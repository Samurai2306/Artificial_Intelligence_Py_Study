{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Объединенные рабочие тетради 5-8\n",
        "\n",
        "Это объединенный файл, содержащий все задания из рабочих тетрадей 5, 6, 7 и 8.\n",
        "\n",
        "**Содержание:**\n",
        "\n",
        "- РТ 5: Деревья решений, ООП\n",
        "- РТ 6: Генетические алгоритмы, имитация отжига\n",
        "- РТ 7: Нейронные сети (персептрон, TensorFlow, Keras, CNN)\n",
        "- РТ 8: Кластеризация (k-means, иерархическая кластеризация)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# РТ 5\n",
        "\n",
        "деревья решений ооп\n",
        "\n",
        "изучение основ ООП в Python и применение деревьев решений для задач классификации и регрессии.\n",
        "\n",
        "ТО ЧТО ВНИЗУ ОБЯЗАТЕЛЬНО ЗАПУСТИТЬ ЕСЛИ НЕ В КОЛАБЕ ОТКРЫТО, ПОТОМУ ЧТО ПИТОН ТВАРЬ И НЕ ВКЛЮЧАЕТ НУЖНЫЕ БИБЛИОТЕКИ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install -q scikit-learn numpy pandas matplotlib scipy seaborn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ооп\n",
        "\n",
        "1. пример - Система обучения\n",
        "\n",
        "Задача: Разработать виртуальную модель процесса обучения. В программе должны быть объекты-ученики, учитель, кладезь знаний.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.2.1 - Система обучения с использованием ООП\n",
        "import numpy as np\n",
        "\n",
        "class Knowledge:\n",
        "    \"\"\"Класс для представления знаний\"\"\"\n",
        "    def __init__(self, subject, content):\n",
        "        self.subject = subject\n",
        "        self.content = content\n",
        "        \n",
        "    def __str__(self):\n",
        "        return f\"Знания по {self.subject}: {self.content}\"\n",
        "\n",
        "class Person:\n",
        "    \"\"\"Базовый класс для представления человека\"\"\"\n",
        "    def __init__(self, name, age):\n",
        "        self.name = name\n",
        "        self.age = age\n",
        "        self.knowledge_base = []\n",
        "    \n",
        "    def add_knowledge(self, knowledge):\n",
        "        \"\"\"Добавить знание\"\"\"\n",
        "        self.knowledge_base.append(knowledge)\n",
        "        \n",
        "    def show_knowledge(self):\n",
        "        \"\"\"Показать все знания\"\"\"\n",
        "        print(f\"\\nЗнания {self.name}:\")\n",
        "        if not self.knowledge_base:\n",
        "            print(\"  Пока нет знаний\")\n",
        "        for k in self.knowledge_base:\n",
        "            print(f\"  - {k}\")\n",
        "\n",
        "class Teacher(Person):\n",
        "    \"\"\"Класс учителя, наследуется от Person\"\"\"\n",
        "    def __init__(self, name, age, subject):\n",
        "        super().__init__(name, age)\n",
        "        self.subject = subject\n",
        "        \n",
        "    def teach(self, student, knowledge):\n",
        "        \"\"\"Обучить студента\"\"\"\n",
        "        print(f\"\\n{self.name} обучает {student.name} предмету: {knowledge.subject}\")\n",
        "        student.learn(knowledge)\n",
        "        \n",
        "    def evaluate(self, student):\n",
        "        \"\"\"Оценить студента\"\"\"\n",
        "        knowledge_count = len(student.knowledge_base)\n",
        "        if knowledge_count >= 3:\n",
        "            grade = \"Отлично\"\n",
        "        elif knowledge_count >= 2:\n",
        "            grade = \"Хорошо\"\n",
        "        elif knowledge_count >= 1:\n",
        "            grade = \"Удовлетворительно\"\n",
        "        else:\n",
        "            grade = \"Неудовлетворительно\"\n",
        "        \n",
        "        print(f\"\\n{self.name} оценивает {student.name}: {grade} (знаний: {knowledge_count})\")\n",
        "        return grade\n",
        "\n",
        "class Student(Person):\n",
        "    \"\"\"Класс студента, наследуется от Person\"\"\"\n",
        "    def __init__(self, name, age):\n",
        "        super().__init__(name, age)\n",
        "        self.grades = []\n",
        "        \n",
        "    def learn(self, knowledge):\n",
        "        \"\"\"Изучить знание\"\"\"\n",
        "        self.add_knowledge(knowledge)\n",
        "        print(f\"  {self.name} изучил: {knowledge}\")\n",
        "        \n",
        "    def receive_grade(self, grade):\n",
        "        \"\"\"Получить оценку\"\"\"\n",
        "        self.grades.append(grade)\n",
        "        print(f\"  {self.name} получил оценку: {grade}\")\n",
        "\n",
        "# демонстрация работы системы\n",
        "print(\"---\")\n",
        "print(\"---\")\n",
        "\n",
        "# создаем знания\n",
        "k1 = Knowledge(\"Python\", \"Основы программирования на Python\")\n",
        "k2 = Knowledge(\"Machine Learning\", \"Алгоритмы машинного обучения\")\n",
        "k3 = Knowledge(\"Data Science\", \"Анализ данных и визуализация\")\n",
        "k4 = Knowledge(\"Deep Learning\", \"Нейронные сети\")\n",
        "\n",
        "# создаем учителя\n",
        "teacher = Teacher(\"Иван Иванович\", 45, \"Программирование\")\n",
        "\n",
        "# создаем студентов\n",
        "student1 = Student(\"Алексей\", 20)\n",
        "student2 = Student(\"Мария\", 22)\n",
        "\n",
        "# Процесс обучения\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"---\")\n",
        "\n",
        "teacher.teach(student1, k1)\n",
        "teacher.teach(student1, k2)\n",
        "teacher.teach(student1, k3)\n",
        "\n",
        "teacher.teach(student2, k1)\n",
        "teacher.teach(student2, k4)\n",
        "\n",
        "# Показываем знания студентов\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"---\")\n",
        "student1.show_knowledge()\n",
        "student2.show_knowledge()\n",
        "\n",
        "# оценка студентов\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"---\")\n",
        "grade1 = teacher.evaluate(student1)\n",
        "grade2 = teacher.evaluate(student2)\n",
        "\n",
        "student1.receive_grade(grade1)\n",
        "student2.receive_grade(grade2)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"---\")\n",
        "print(f\"{student1.name}: оценки - {student1.grades}, знаний - {len(student1.knowledge_base)}\")\n",
        "print(f\"{student2.name}: оценки - {student2.grades}, знаний - {len(student2.knowledge_base)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Деревья решений\n",
        "\n",
        "Классификация с помощью деревьев решений\n",
        "\n",
        "Задача: Применить алгоритм дерева решений на датасете Iris для классификации видов ирисов.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# - Деревья решений для классификации\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# загрузка данные Iris\n",
        "df = pd.read_csv('data/iris.csv')\n",
        "\n",
        "print(\"Датасет Iris:\")\n",
        "print(df.head())\n",
        "\n",
        "# подготовка данных\n",
        "X = df.drop('variety', axis=1).values\n",
        "y = df['variety'].values\n",
        "feature_names = df.drop('variety', axis=1).columns.tolist()\n",
        "\n",
        "# тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"\\nОбучающая выборка: {X_train.shape[0]}\")\n",
        "print(f\"Тестовая выборка: {X_test.shape[0]}\")\n",
        "\n",
        "# дерева решений\n",
        "dt_model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# прогноз\n",
        "y_pred = dt_model.predict(X_test)\n",
        "\n",
        "# оценка качества\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Точность модели: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "\n",
        "print(f\"\\nОтчет классификации:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Важность признаков\n",
        "feature_importance = dt_model.feature_importances_\n",
        "print(f\"\\nВажность признаков:\")\n",
        "for feature, importance in zip(feature_names, feature_importance):\n",
        "    print(f\"  {feature:20s}: {importance:.4f}\")\n",
        "\n",
        "# визуализация дерева решений\n",
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(dt_model, \n",
        "          feature_names=feature_names,\n",
        "          class_names=sorted(df['variety'].unique()),\n",
        "          filled=True, \n",
        "          rounded=True,\n",
        "          fontsize=10)\n",
        "plt.title('Дерево решений для классификации ирисов', fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# визуализация важности признаков\n",
        "plt.figure(figsize=(10, 6))\n",
        "sorted_idx = np.argsort(feature_importance)[::-1]\n",
        "plt.barh(range(len(feature_importance)), feature_importance[sorted_idx], color='skyblue', edgecolor='black')\n",
        "plt.yticks(range(len(feature_importance)), [feature_names[i] for i in sorted_idx])\n",
        "plt.xlabel('Важность признака', fontsize=12)\n",
        "plt.title('Важность признаков в дереве решений', fontsize=14)\n",
        "plt.grid(True, alpha=0.3, axis='x')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nДерево решений показало высокую точность классификации на датасете Iris.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# РТ 6\n",
        "\n",
        "генетика отжиг\n",
        "\n",
        "изучение эволюционных алгоритмов (генетические алгоритмы) и метода имитации отжига для решения задач оптимизации.\n",
        "\n",
        "ТО ЧТО ВНИЗУ ОБЯЗАТЕЛЬНО ЗАПУСТИТЬ ЕСЛИ НЕ В КОЛАБЕ ОТКРЫТО, ПОТОМУ ЧТО ПИТОН ТВАРЬ И НЕ ВКЛЮЧАЕТ НУЖНЫЕ БИБЛИОТЕКИ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install -q scikit-learn numpy pandas matplotlib scipy seaborn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## генетика\n",
        "\n",
        "1. пример - Генетический алгоритм\n",
        "\n",
        "Задача: Реализовать генетический алгоритм для оптимизации функции. Даны начальные хромосомы с двумя генами x и y. Показатель качества хромосомы оценивается функцией Z. Необходимо выполнить эволюцию популяции.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# - Генетический алгоритм\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class GeneticAlgorithm:\n",
        "    \"\"\"Класс для реализации генетического алгоритма\"\"\"\n",
        "    \n",
        "    def __init__(self, fitness_function, pop_size=4, num_genes=2):\n",
        "        self.fitness_function = fitness_function\n",
        "        self.pop_size = pop_size\n",
        "        self.num_genes = num_genes\n",
        "        self.population = []\n",
        "        self.history = []\n",
        "        \n",
        "    def initialize_population(self, initial_pop):\n",
        "        \"\"\"Инициализация начальной популяции\"\"\"\n",
        "        self.population = initial_pop.copy()\n",
        "        \n",
        "    def evaluate_fitness(self):\n",
        "        \"\"\"Оценка качества всех хромосом\"\"\"\n",
        "        fitness_values = []\n",
        "        for chromosome in self.population:\n",
        "            fitness = self.fitness_function(chromosome)\n",
        "            fitness_values.append(fitness)\n",
        "        return np.array(fitness_values)\n",
        "    \n",
        "    def crossover(self, parent1, parent2):\n",
        "        \"\"\"Кроссовер (скрещивание) двух родителей\"\"\"\n",
        "        # Одноточечное скрещивание\n",
        "        crossover_point = len(parent1) // 2\n",
        "        child1 = np.concatenate([parent1[:crossover_point], parent2[crossover_point:]])\n",
        "        child2 = np.concatenate([parent2[:crossover_point], parent1[crossover_point:]])\n",
        "        return child1, child2\n",
        "    \n",
        "    def mutate(self, chromosome, mutation_rate=0.1):\n",
        "        \"\"\"Мутация хромосомы\"\"\"\n",
        "        for i in range(len(chromosome)):\n",
        "            if np.random.random() < mutation_rate:\n",
        "                chromosome[i] += np.random.normal(0, 0.5)\n",
        "        return chromosome\n",
        "    \n",
        "    def evolve(self, num_generations=10):\n",
        "        \"\"\"Эволюция популяции\"\"\"\n",
        "        print(\"---\")\n",
        "        print(\"---\")\n",
        "        \n",
        "        for generation in range(num_generations):\n",
        "            # оценка качества\n",
        "            fitness_values = self.evaluate_fitness()\n",
        "            \n",
        "            # Сохраняем историю\n",
        "            best_fitness = np.max(fitness_values)\n",
        "            avg_fitness = np.mean(fitness_values)\n",
        "            self.history.append({\n",
        "                'generation': generation,\n",
        "                'best_fitness': best_fitness,\n",
        "                'avg_fitness': avg_fitness,\n",
        "                'population': self.population.copy()\n",
        "            })\n",
        "            \n",
        "            print(f\"\\nПоколение {generation + 1}:\")\n",
        "            print(f\"  Лучшее качество: {best_fitness:.4f}\")\n",
        "            print(f\"  Среднее качество: {avg_fitness:.4f}\")\n",
        "            \n",
        "            #\n",
        "            sorted_indices = np.argsort(fitness_values)[::-1]\n",
        "            sorted_population = [self.population[i] for i in sorted_indices]\n",
        "            \n",
        "            # Селекция - выбираем лучших\n",
        "            parents = sorted_population[:2]\n",
        "            \n",
        "            # Кроссовер\n",
        "            offspring = []\n",
        "            for i in range(self.pop_size // 2):\n",
        "                child1, child2 = self.crossover(parents[0], parents[1])\n",
        "                offspring.append(child1)\n",
        "                offspring.append(child2)\n",
        "            \n",
        "            # Мутация\n",
        "            for i in range(len(offspring)):\n",
        "                offspring[i] = self.mutate(offspring[i])\n",
        "            \n",
        "            # Формируем новое поколение\n",
        "            self.population = offspring\n",
        "        \n",
        "        # Финальная оценка\n",
        "        final_fitness = self.evaluate_fitness()\n",
        "        best_idx = np.argmax(final_fitness)\n",
        "        \n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"Лучшая хромосома: {self.population[best_idx]}\")\n",
        "        print(f\"Лучшее качество: {final_fitness[best_idx]:.4f}\")\n",
        "        \n",
        "        return self.population[best_idx], final_fitness[best_idx]\n",
        "\n",
        "# определяем функцию качества (фитнес-функцию)\n",
        "def fitness_function(chromosome):\n",
        "    \"\"\"Функция качества: Z = x^2 + y^2 + 2*x*y\"\"\"\n",
        "    x, y = chromosome\n",
        "    return x**2 + y**2 + 2*x*y\n",
        "\n",
        "# инициализация начальной популяции\n",
        "initial_population = [\n",
        "    np.array([1.0, 2.0]),\n",
        "    np.array([2.0, 1.0]),\n",
        "    np.array([3.0, 3.0]),\n",
        "    np.array([1.5, 2.5])\n",
        "]\n",
        "\n",
        "# алгоритма\n",
        "ga = GeneticAlgorithm(fitness_function, pop_size=4, num_genes=2)\n",
        "ga.initialize_population(initial_population)\n",
        "\n",
        "# Эволюция\n",
        "best_chromosome, best_fitness = ga.evolve(num_generations=10)\n",
        "\n",
        "# визуализация процесса эволюции\n",
        "generations = [h['generation'] for h in ga.history]\n",
        "best_fitness_history = [h['best_fitness'] for h in ga.history]\n",
        "avg_fitness_history = [h['avg_fitness'] for h in ga.history]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(generations, best_fitness_history, 'o-', linewidth=2, markersize=8, label='Лучшее качество', color='green')\n",
        "plt.plot(generations, avg_fitness_history, 's-', linewidth=2, markersize=8, label='Среднее качество', color='blue')\n",
        "plt.xlabel('Поколение', fontsize=12)\n",
        "plt.ylabel('Качество (fitness)', fontsize=12)\n",
        "plt.title('Эволюция популяции в генетическом алгоритме', fontsize=14)\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nГенетический алгоритм успешно оптимизировал функцию качества через эволюцию популяции.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## отжиг\n",
        "\n",
        "пример - Имитация отжига для оптимизации\n",
        "\n",
        "Задача: Реализовать метод имитации отжига для поиска оптимального решения. Метод моделирует процесс физического отжига металла.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# - Метод имитации отжига\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class SimulatedAnnealing:\n",
        "    \"\"\"Класс для реализации метода имитации отжига\"\"\"\n",
        "    \n",
        "    def __init__(self, objective_function, initial_solution, initial_temp=100, cooling_rate=0.95):\n",
        "        self.objective_function = objective_function\n",
        "        self.current_solution = initial_solution.copy()\n",
        "        self.best_solution = initial_solution.copy()\n",
        "        self.current_cost = objective_function(initial_solution)\n",
        "        self.best_cost = self.current_cost\n",
        "        self.temperature = initial_temp\n",
        "        self.cooling_rate = cooling_rate\n",
        "        self.history = []\n",
        "        \n",
        "    def generate_neighbor(self, solution):\n",
        "        \"\"\"Генерация соседнего решения\"\"\"\n",
        "        neighbor = solution.copy()\n",
        "        #\n",
        "        idx = np.random.randint(0, len(solution))\n",
        "        neighbor[idx] += np.random.uniform(-1, 1)\n",
        "        return neighbor\n",
        "    \n",
        "    def acceptance_probability(self, current_cost, new_cost, temperature):\n",
        "        \"\"\"Вероятность принятия нового решения\"\"\"\n",
        "        if new_cost < current_cost:\n",
        "            return 1.0\n",
        "        else:\n",
        "            return np.exp(-(new_cost - current_cost) / temperature)\n",
        "    \n",
        "    def optimize(self, max_iterations=1000):\n",
        "        \"\"\"Процесс оптимизации\"\"\"\n",
        "        print(\"---\")\n",
        "        print(\"---\")\n",
        "        print(f\"Начальное решение: {self.current_solution}\")\n",
        "        print(f\"Начальная стоимость: {self.current_cost:.4f}\")\n",
        "        print(f\"Начальная температура: {self.temperature}\")\n",
        "        \n",
        "        for iteration in range(max_iterations):\n",
        "            # Генерируем соседнее решение\n",
        "            new_solution = self.generate_neighbor(self.current_solution)\n",
        "            new_cost = self.objective_function(new_solution)\n",
        "            \n",
        "            # Решаем, принять ли новое решение\n",
        "            acceptance_prob = self.acceptance_probability(self.current_cost, new_cost, self.temperature)\n",
        "            \n",
        "            if acceptance_prob > np.random.random():\n",
        "                self.current_solution = new_solution\n",
        "                self.current_cost = new_cost\n",
        "                \n",
        "                # Обновляем лучшее решение\n",
        "                if new_cost < self.best_cost:\n",
        "                    self.best_solution = new_solution.copy()\n",
        "                    self.best_cost = new_cost\n",
        "            \n",
        "            # Сохраняем историю\n",
        "            self.history.append({\n",
        "                'iteration': iteration,\n",
        "                'temperature': self.temperature,\n",
        "                'current_cost': self.current_cost,\n",
        "                'best_cost': self.best_cost\n",
        "            })\n",
        "            \n",
        "            # Охлаждение\n",
        "            self.temperature *= self.cooling_rate\n",
        "            \n",
        "            # Вывод промежуточных результатов\n",
        "            if (iteration + 1) % 100 == 0:\n",
        "                print(f\"\\nИтерация {iteration + 1}:\")\n",
        "                print(f\"  Текущая температура: {self.temperature:.4f}\")\n",
        "                print(f\"  Текущая стоимость: {self.current_cost:.4f}\")\n",
        "                print(f\"  Лучшая стоимость: {self.best_cost:.4f}\")\n",
        "        \n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"Лучшее решение: {self.best_solution}\")\n",
        "        print(f\"Лучшая стоимость: {self.best_cost:.4f}\")\n",
        "        \n",
        "        return self.best_solution, self.best_cost\n",
        "\n",
        "# определяем функцию цели (целевую функцию для минимизации)\n",
        "def objective_function(solution):\n",
        "    \"\"\"Функция Растригина (тестовая функция оптимизации)\"\"\"\n",
        "    A = 10\n",
        "    n = len(solution)\n",
        "    return A * n + sum([(x**2 - A * np.cos(2 * np.pi * x)) for x in solution])\n",
        "\n",
        "# Начальное решение (случайная точка)\n",
        "np.random.seed(42)\n",
        "initial_solution = np.random.uniform(-5, 5, 2)\n",
        "\n",
        "# имитации отжига\n",
        "sa = SimulatedAnnealing(\n",
        "    objective_function=objective_function,\n",
        "    initial_solution=initial_solution,\n",
        "    initial_temp=100,\n",
        "    cooling_rate=0.95\n",
        ")\n",
        "\n",
        "# Оптимизация\n",
        "best_solution, best_cost = sa.optimize(max_iterations=1000)\n",
        "\n",
        "# визуализация процесса оптимизации\n",
        "iterations = [h['iteration'] for h in sa.history]\n",
        "temperatures = [h['temperature'] for h in sa.history]\n",
        "current_costs = [h['current_cost'] for h in sa.history]\n",
        "best_costs = [h['best_cost'] for h in sa.history]\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
        "\n",
        "# График 1: Стоимость решений\n",
        "ax1.plot(iterations, current_costs, alpha=0.5, label='Текущая стоимость', color='lightblue')\n",
        "ax1.plot(iterations, best_costs, linewidth=2, label='Лучшая стоимость', color='green')\n",
        "ax1.set_xlabel('Итерация', fontsize=12)\n",
        "ax1.set_ylabel('Стоимость', fontsize=12)\n",
        "ax1.set_title('Процесс оптимизации методом имитации отжига', fontsize=14)\n",
        "ax1.legend(fontsize=11)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# График 2: Изменение температуры\n",
        "ax2.plot(iterations, temperatures, linewidth=2, color='red')\n",
        "ax2.set_xlabel('Итерация', fontsize=12)\n",
        "ax2.set_ylabel('Температура', fontsize=12)\n",
        "ax2.set_title('Снижение температуры', fontsize=14)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nМетод имитации отжига успешно нашел приближенное оптимальное решение.\")\n",
        "print(\"Начальная температура позволяет исследовать пространство решений,\")\n",
        "print(\"а постепенное охлаждение обеспечивает сходимость к локальному минимуму.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# РТ 7: Нейронные сети\n",
        "\n",
        "Изучение нейронных сетей: персептрон, TensorFlow, Keras\n",
        "\n",
        "**Содержание:**\n",
        "\n",
        "- Часть 1: Обучение персептрона\n",
        "- Часть 2: TensorFlow и Keras\n",
        "- Примеры нейронных сетей для классификации\n",
        "- Сверточные нейронные сети (CNN)\n",
        "\n",
        "ТО ЧТО ВНИЗУ ОБЯЗАТЕЛЬНО ЗАПУСТИТЬ ЕСЛИ НЕ В КОЛАБЕ ОТКРЫТО\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install -q numpy pandas matplotlib scikit-learn scipy seaborn tensorflow keras\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Часть 1: Обучение персептрона\n",
        "\n",
        "Персептрон - это элементарная часть нейронной сети, линейный бинарный классификатор.\n",
        "\n",
        "### Пример - Класс персептрона на Python\n",
        "\n",
        "Реализация класса персептрона, который умеет учиться на тестовых данных.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    \"\"\"\n",
        "    Класс персептрона для бинарной классификации\n",
        "    \"\"\"\n",
        "    def __init__(self, n_inputs, learning_rate=0.1):\n",
        "        \"\"\"\n",
        "        n_inputs - количество входов\n",
        "        learning_rate - скорость обучения\n",
        "        \"\"\"\n",
        "        self.weights = np.zeros(n_inputs + 1)  # +1 для порога w0\n",
        "        self.learning_rate = learning_rate\n",
        "    \n",
        "    def predict(self, inputs):\n",
        "        \"\"\"\n",
        "        Вычисление выхода персептрона\n",
        "        \"\"\"\n",
        "        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]\n",
        "        return 1 if summation >= 0 else -1\n",
        "    \n",
        "    def train(self, training_inputs, labels, epochs=10):\n",
        "        \"\"\"\n",
        "        Обучение персептрона\n",
        "        \"\"\"\n",
        "        for epoch in range(epochs):\n",
        "            errors = 0\n",
        "            for inputs, label in zip(training_inputs, labels):\n",
        "                prediction = self.predict(inputs)\n",
        "                # Корректировка весов при ошибке\n",
        "                if prediction * label < 0:\n",
        "                    self.weights[1:] += self.learning_rate * label * inputs\n",
        "                    self.weights[0] += self.learning_rate * label\n",
        "                    errors += 1\n",
        "            print(f\"Эпоха {epoch + 1}: ошибок = {errors}\")\n",
        "            if errors == 0:\n",
        "                print(\"Обучение завершено!\")\n",
        "                break\n",
        "\n",
        "# Тестируем персептрон\n",
        "# Обучающие данные: классифицируем вектора, где первая компонента больше второй (класс 1)\n",
        "# и где первая компонента меньше второй (класс -1)\n",
        "training_data = np.array([\n",
        "    [3, 1],\n",
        "    [4, 2],\n",
        "    [1, 3],\n",
        "    [2, 4],\n",
        "    [5, 2],\n",
        "    [1, 5]\n",
        "])\n",
        "\n",
        "labels = np.array([1, 1, -1, -1, 1, -1])\n",
        "\n",
        "# Создаем и обучаем персептрон\n",
        "perceptron = Perceptron(n_inputs=2, learning_rate=0.1)\n",
        "print(\"Начальные веса:\", perceptron.weights)\n",
        "print(\"\\nОбучение персептрона:\")\n",
        "perceptron.train(training_data, labels, epochs=10)\n",
        "print(\"\\nИтоговые веса:\", perceptron.weights)\n",
        "\n",
        "# Тестируем\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Тестирование персептрона:\")\n",
        "print(\"=\"*60)\n",
        "test_data = [[6, 2], [2, 6], [3, 3], [5, 1]]\n",
        "for test in test_data:\n",
        "    prediction = perceptron.predict(test)\n",
        "    print(f\"Вход {test} → Класс {prediction}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Часть 2: Scikit-Learn - MLPClassifier и MLPRegressor\n",
        "\n",
        "### Задание - Классификация и регрессия с использованием Scikit-Learn\n",
        "\n",
        "**Задача:** Использовать MLPClassifier для классификации Ирисов и MLPRegressor для регрессии зарплаты от опыта работы.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "\n",
        "# ========== ЧАСТЬ 1: Классификация Ирисов ==========\n",
        "print(\"=\"*70)\n",
        "print(\"КЛАССИФИКАЦИЯ ИРИСОВ С ИСПОЛЬЗОВАНИЕМ MLPClassifier\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Загрузка данных Iris\n",
        "df_iris = pd.read_csv('data/iris.csv')\n",
        "\n",
        "print(f\"\\nРазмер датасета: {df_iris.shape}\")\n",
        "print(f\"Классы: {df_iris['variety'].unique()}\")\n",
        "\n",
        "# Подготовка данных\n",
        "X_iris = df_iris.drop('variety', axis=1).values\n",
        "y_iris = df_iris['variety'].values\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(\n",
        "    X_iris, y_iris, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Нормализация данных\n",
        "scaler_iris = StandardScaler()\n",
        "X_train_iris_scaled = scaler_iris.fit_transform(X_train_iris)\n",
        "X_test_iris_scaled = scaler_iris.transform(X_test_iris)\n",
        "\n",
        "# Создание и обучение MLPClassifier\n",
        "mlp_classifier = MLPClassifier(\n",
        "    hidden_layer_sizes=(10, 10),  # Два скрытых слоя по 10 нейронов\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=1000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"\\nОбучение модели MLPClassifier...\")\n",
        "mlp_classifier.fit(X_train_iris_scaled, y_train_iris)\n",
        "\n",
        "# Предсказание\n",
        "y_pred_iris = mlp_classifier.predict(X_test_iris_scaled)\n",
        "\n",
        "# Оценка качества\n",
        "accuracy = accuracy_score(y_test_iris, y_pred_iris)\n",
        "print(f\"\\nТочность модели: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "\n",
        "print(\"\\nОтчет классификации:\")\n",
        "print(classification_report(y_test_iris, y_pred_iris))\n",
        "\n",
        "# ========== ЧАСТЬ 2: Регрессия зарплаты ==========\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"РЕГРЕССИЯ ЗАРПЛАТЫ ОТ ОПЫТА С ИСПОЛЬЗОВАНИЕМ MLPRegressor\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Загрузка данных о зарплатах\n",
        "df_salary = pd.read_csv('data/Salary_Data.csv')\n",
        "\n",
        "print(f\"\\nРазмер датасета: {df_salary.shape}\")\n",
        "\n",
        "# Подготовка данных\n",
        "X_salary = df_salary[['YearsExperience']].values\n",
        "y_salary = df_salary['Salary'].values\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train_salary, X_test_salary, y_train_salary, y_test_salary = train_test_split(\n",
        "    X_salary, y_salary, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Нормализация данных\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "X_train_salary_scaled = scaler_X.fit_transform(X_train_salary)\n",
        "X_test_salary_scaled = scaler_X.transform(X_test_salary)\n",
        "y_train_salary_scaled = scaler_y.fit_transform(y_train_salary.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Создание и обучение MLPRegressor\n",
        "mlp_regressor = MLPRegressor(\n",
        "    hidden_layer_sizes=(20, 20),  # Два скрытых слоя по 20 нейронов\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=2000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"\\nОбучение модели MLPRegressor...\")\n",
        "mlp_regressor.fit(X_train_salary_scaled, y_train_salary_scaled)\n",
        "\n",
        "# Предсказание\n",
        "y_pred_salary_scaled = mlp_regressor.predict(X_test_salary_scaled)\n",
        "y_pred_salary = scaler_y.inverse_transform(y_pred_salary_scaled.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Оценка качества\n",
        "r2 = r2_score(y_test_salary, y_pred_salary)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_salary, y_pred_salary))\n",
        "\n",
        "print(f\"\\nR² (коэффициент детерминации): {r2:.4f}\")\n",
        "print(f\"RMSE (среднеквадратичная ошибка): ${rmse:.2f}\")\n",
        "\n",
        "print(\"\\nЗадание выполнено успешно!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# РТ 8: Кластеризация\n",
        "\n",
        "Изучение методов кластеризации данных\n",
        "\n",
        "**Содержание:**\n",
        "\n",
        "- Метод k-средних (k-means)\n",
        "- Иерархическая кластеризация\n",
        "- Применение на реальных данных\n",
        "\n",
        "ТО ЧТО ВНИЗУ ОБЯЗАТЕЛЬНО ЗАПУСТИТЬ ЕСЛИ НЕ В КОЛАБЕ ОТКРЫТО\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install -q numpy pandas matplotlib scikit-learn scipy seaborn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Часть 1: Метод k-средних (k-means)\n",
        "\n",
        "Кластеризация — разбиение множества объектов на подмножества (кластеры) так, чтобы объекты в одном кластере были схожи, а в разных — различались.\n",
        "\n",
        "### Пример - Генерация данных и применение k-means\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "# Генерируем 2D-набор данных с 4 кластерами\n",
        "X, y_true = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0)\n",
        "\n",
        "print(\"Генерация данных с 4 кластерами\")\n",
        "print(f\"Размер данных: {X.shape}\")\n",
        "print(f\"Истинные метки (для визуализации): {np.unique(y_true)}\")\n",
        "\n",
        "# Визуализация исходных данных\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(X[:, 0], X[:, 1], s=50, alpha=0.6, edgecolors='black')\n",
        "plt.title('Исходные данные (без меток)')\n",
        "plt.xlabel('Признак 1')\n",
        "plt.ylabel('Признак 2')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Применяем k-means с k=4\n",
        "kmeans = KMeans(n_clusters=4, random_state=0, n_init=10)\n",
        "y_kmeans = kmeans.fit_predict(X)\n",
        "\n",
        "# Визуализация результатов кластеризации\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis', \n",
        "            alpha=0.6, edgecolors='black')\n",
        "# Отображаем центроиды\n",
        "centers = kmeans.cluster_centers_\n",
        "plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.8, \n",
        "            marker='X', edgecolors='black', linewidths=2, label='Центроиды')\n",
        "plt.title('Результат k-means кластеризации (k=4)')\n",
        "plt.xlabel('Признак 1')\n",
        "plt.ylabel('Признак 2')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nЦентры кластеров:\")\n",
        "for i, center in enumerate(centers):\n",
        "    print(f\"  Кластер {i}: {center}\")\n",
        "    \n",
        "print(f\"\\nИнерция (сумма квадратов расстояний до центроидов): {kmeans.inertia_:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Задание 2 - Кластеризация набора данных ирисов Фишера\n",
        "\n",
        "**Задача:** Выполнить кластеризацию для набора данных ирисов. Поэкспериментировать с количеством кластеров.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Загрузка данных ирисов\n",
        "df_iris = pd.read_csv('data/iris.csv')\n",
        "\n",
        "print(\"Набор данных Iris:\")\n",
        "print(df_iris.head())\n",
        "print(f\"\\nРазмер: {df_iris.shape}\")\n",
        "print(f\"Классы: {df_iris['variety'].unique()}\")\n",
        "\n",
        "# Подготовка данных (используем только числовые признаки)\n",
        "X_iris = df_iris.drop('variety', axis=1).values\n",
        "y_true = df_iris['variety'].values\n",
        "\n",
        "# Нормализация данных\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_iris)\n",
        "\n",
        "# Экспериментируем с разным количеством кластеров\n",
        "k_values = [2, 3, 4, 5]\n",
        "\n",
        "# Визуализация в 2D (используем первые два признака)\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "\n",
        "for idx, k in enumerate(k_values):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    clusters = kmeans.fit_predict(X_scaled)\n",
        "    \n",
        "    ax = axes[idx // 2, idx % 2]\n",
        "    scatter = ax.scatter(df_iris['sepal.length'], df_iris['sepal.width'],\n",
        "                        c=clusters, s=100, cmap='viridis', alpha=0.6, \n",
        "                        edgecolors='black')\n",
        "    ax.set_title(f'k = {k} кластеров (Инерция: {kmeans.inertia_:.2f})', fontsize=12)\n",
        "    ax.set_xlabel('Длина чашелистика', fontsize=11)\n",
        "    ax.set_ylabel('Ширина чашелистика', fontsize=11)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.colorbar(scatter, ax=ax, label='Кластер')\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"k = {k}:\")\n",
        "    print(f\"  Инерция: {kmeans.inertia_:.2f}\")\n",
        "    \n",
        "    # Анализ соответствия кластеров истинным классам\n",
        "    for cluster_id in range(k):\n",
        "        mask = clusters == cluster_id\n",
        "        species_in_cluster = y_true[mask]\n",
        "        unique, counts = np.unique(species_in_cluster, return_counts=True)\n",
        "        print(f\"  Кластер {cluster_id}: {dict(zip(unique, counts))}\")\n",
        "\n",
        "plt.suptitle('Кластеризация Iris с разным k (sepal.length vs sepal.width)', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ВЫВОД:\")\n",
        "print(\"=\"*60)\n",
        "print(\"Оптимальное количество кластеров k = 3 (соответствует трём видам ирисов)\")\n",
        "print(\"При k=3 кластеризация хорошо соответствует истинным классам\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Загрузка данных ирисов\n",
        "df_iris = pd.read_csv('data/iris.csv')\n",
        "\n",
        "print(\"Иерархическая кластеризация набора данных Iris\")\n",
        "print(\"=\"*60)\n",
        "print(\"Используем признаки: petal.length и petal.width\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Выбираем два признака для визуализации\n",
        "X_2d = df_iris[['petal.length', 'petal.width']].values\n",
        "y_true = df_iris['variety'].values\n",
        "\n",
        "# Нормализация данных\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_2d)\n",
        "\n",
        "print(f\"\\nРазмер данных: {X_scaled.shape}\")\n",
        "\n",
        "# Построение дендрограммы\n",
        "print(\"\\nПостроение дендрограммы...\")\n",
        "Z = linkage(X_scaled, method='ward')\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "dendrogram(Z, truncate_mode='lastp', p=30, show_leaf_counts=True)\n",
        "plt.title('Дендрограмма для Iris (petal.length vs petal.width)', fontsize=14)\n",
        "plt.xlabel('Индекс кластера / Количество точек', fontsize=12)\n",
        "plt.ylabel('Расстояние', fontsize=12)\n",
        "plt.axhline(y=7, color='r', linestyle='--', linewidth=2, label='Порог для 3 кластеров')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3, axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nПо дендрограмме видно, что оптимальное количество кластеров = 3\")\n",
        "\n",
        "# Применяем иерархическую кластеризацию с разным количеством кластеров\n",
        "cluster_numbers = [2, 3, 4, 5]\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "\n",
        "for idx, n_clusters in enumerate(cluster_numbers):\n",
        "    hc = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
        "    labels = hc.fit_predict(X_scaled)\n",
        "    \n",
        "    ax = axes[idx // 2, idx % 2]\n",
        "    scatter = ax.scatter(df_iris['petal.length'], df_iris['petal.width'],\n",
        "                        c=labels, s=100, cmap='viridis', alpha=0.6, \n",
        "                        edgecolors='black', linewidths=1.5)\n",
        "    \n",
        "    ax.set_title(f'{n_clusters} кластера', fontsize=13)\n",
        "    ax.set_xlabel('Длина лепестка (petal.length)', fontsize=11)\n",
        "    ax.set_ylabel('Ширина лепестка (petal.width)', fontsize=11)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.colorbar(scatter, ax=ax, label='Кластер')\n",
        "    \n",
        "    # Анализ соответствия\n",
        "    print(f\"\\n{n_clusters} кластера:\")\n",
        "    for cluster_id in range(n_clusters):\n",
        "        mask = labels == cluster_id\n",
        "        species_in_cluster = y_true[mask]\n",
        "        unique, counts = np.unique(species_in_cluster, return_counts=True)\n",
        "        print(f\"  Кластер {cluster_id}: {dict(zip(unique, counts))}\")\n",
        "\n",
        "plt.suptitle('Иерархическая кластеризация Iris с разным количеством кластеров', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nЗадание выполнено!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
